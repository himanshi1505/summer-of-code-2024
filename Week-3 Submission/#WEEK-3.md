#WEEK-3
In Week 3, I delved into K-means Clustering and DBSCAN. I began with a customer analysis dataset, performing preprocessing and feature engineering. I plotted selected features to identify and remove outliers, followed by feature scaling. I then applied Principal Component Analysis (PCA) to reduce dimensions. Initially, I used Agglomerative clustering, determining the optimal number of clusters (k=4) using the elbow method. The model evaluation revealed fairly distributed clusters, with cluster 1 being the largest set of customers closely followed by cluster 0. I further profiled customers within these clusters based on their family structures and income/spending patterns. Subsequently, I applied DBSCAN and evaluated the model. However, this dataset proved inadequate for building a recommendation system, leading me to switch to an Ecommerce dataset. I repeated preprocessing and feature engineering, added RFM features, removed outliers, performed feature scaling, and applied dimensionality reduction. Using the elbow method, I determined the optimal number of clusters (k=3), and after that I did evaluation and profiling.The resulting clusters were almost equally distributed. I then explored TF-IDF Vectorization and Cosine Similarity to recommend similar products to customers. Facing difficulties with the utility of vectorization, I opted for cosine similarity and clustering to recommend the top three products. Given the computational load of recommending for thousands of entries, I limited the recommendations to 10 random customer IDs.